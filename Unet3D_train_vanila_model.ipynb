{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5118,
     "status": "ok",
     "timestamp": 1700319865615,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "M2jrjG-6Y4jy"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import nibabel as nib\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg5v9ZnsqCk7"
   },
   "source": [
    "# 3D UNET\n",
    "- the model of 3D UNET is provided at <mark> from classes.models.unet3d import UNet3D </mark>\n",
    "They are few important parameters that are essential to extract features better.\n",
    "- The UNET model uses 3D convolution. It has 4 layers in the model.\n",
    "- Default kernel size for Double convolution is 3 or (3x3x3)\n",
    "- Number of features channels: Increase the number of channels for features enable prediction of classes.\n",
    "- channel selector 0: (4, 8, 16, 32, 64) and kernel size 3has failed to extract any class but background.\n",
    "- Channel selector 1, with channels (8, 16, 32, 64, 128) and a kernel size of 3, can effectively segment the kidney. However, it is unable to successfully predict features for tumors and cysts.\n",
    "- channel selector 2: (16, 32, 64, 128, 256) and kernel size 5, can obtain segmentation for kidney well and tumor can also be predicted. However, feature of cyst still can not be extracted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700319865616,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "Fzr0fn45ZWja"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./\"\n",
    "raw_dataset_dir = \"dataset/\"\n",
    "transformed_dataset_dir_path = \"dataset/affine_transformed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1700319866161,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "8Uor3sVciNlr",
    "outputId": "e966f848-3acb-411a-fdf6-fa4a0d64b94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset folder exists, OK\n"
     ]
    }
   ],
   "source": [
    "is_colab = True\n",
    "if is_colab:\n",
    "    base_dir = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "    if not os.path.isdir(base_dir):\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "raw_dataset_dir = os.path.join(base_dir, raw_dataset_dir)\n",
    "transformed_dataset_dir_path = os.path.join(base_dir, transformed_dataset_dir_path)\n",
    "\n",
    "if os.path.isdir(raw_dataset_dir) and os.path.isdir(transformed_dataset_dir_path):\n",
    "    print(\"dataset folder exists, OK\")\n",
    "else:\n",
    "    raise Exception(\"check path for dataset:{} \\n path for transformed dataset: {}\"\n",
    "                    .format(raw_dataset_dir, transformed_dataset_dir_path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2993,
     "status": "ok",
     "timestamp": 1700319869151,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "WWiy5eIaia0G"
   },
   "outputs": [],
   "source": [
    "sys.path.append(base_dir)\n",
    "from classes.dataset_utils.toTorchDataset import ProcessedKit23TorchDataset\n",
    "from classes.models.unet3d import UNet3D\n",
    "from classes.epoch_results import EpochResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700319869152,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "sL0Az8MVjTaX"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1700319870124,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "JFSy6pCNZTI7",
    "outputId": "c16a55a6-6a2a-44ef-a5ba-1cb4037624dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data:366    size of testing dat:123\n"
     ]
    }
   ],
   "source": [
    "training_data = ProcessedKit23TorchDataset(train_data=True, test_size=0.25, dataset_dir =transformed_dataset_dir_path)\n",
    "test_data = ProcessedKit23TorchDataset(train_data=False, test_size=0.25, dataset_dir =transformed_dataset_dir_path)\n",
    "print(\"size of training data:{}    size of testing dat:{}\".format(len(training_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuZEHGf9p5P_"
   },
   "source": [
    "## Reduce Training Cases and Test Cases\n",
    "- Following is used to reduce number of Training and Test casess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1700319870124,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "U5wsnRR-aZb_"
   },
   "outputs": [],
   "source": [
    "is_simplified = True\n",
    "# to demo, only 10 test cases are tested.\n",
    "if is_simplified:\n",
    "    training_data.case_dirs = training_data.case_dirs[:100]\n",
    "    training_data.case_names = training_data.case_names[:100]\n",
    "    test_data.case_dirs = test_data.case_dirs[:10]\n",
    "    test_data.case_names = test_data.case_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6451,
     "status": "ok",
     "timestamp": 1700319876573,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "TRU4gVAJZOrd"
   },
   "outputs": [],
   "source": [
    "channel_selection = 1\n",
    "ks = 3\n",
    "is_upsampling = True   # For NOT using CV transpose, use True\n",
    "model = UNet3D(1, 4, channel_selection=channel_selection, double_conv_kernel_size=ks, is_upsampling = True).to(device)\n",
    "model._initialize_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9uwZcPUpg2q"
   },
   "source": [
    "## Optimizer or Gradient Descent Model\n",
    "- Enable choose of ADAM or SGD\n",
    "- Adjust learning rate decay manually. Higher gamma if there are high number of test data. For 100 cases, gamma 0.95 is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1700319878128,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "2gNMg32ZlBj-"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-3)\n",
    "is_ADAM = True\n",
    "if is_ADAM:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2573,
     "status": "ok",
     "timestamp": 1700319880698,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "rIyGyBRZlCI-",
    "outputId": "ccef3c74-58ab-474b-d4a4-284a4962ea98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet3D - loading from trained weight\n"
     ]
    }
   ],
   "source": [
    "continue_from_checkpoint = True\n",
    "epoch_res = EpochResult()\n",
    "epoch_start = 0\n",
    "if continue_from_checkpoint:\n",
    "    print(\"Unet3D - loading from trained weight\")\n",
    "    checkpoint_ref_filepath = None\n",
    "    # this continues from certain training points\n",
    "    if is_ADAM:\n",
    "        # checkpoint_ref_filepath = \"training_checkpoints/Model_UNET_ch2_ks5_epoch7.pth.tar\"\n",
    "        # checkpoint_ref_filepath = \"training_checkpoints/Model_UNET_epoch40.pth.tar\"\n",
    "        checkpoint_ref_filepath = \"training_checkpoints/Model_UNET_ch1_ks3_up_epoch30.pth.tar\"\n",
    "    else:\n",
    "        checkpoint_ref_filepath = \"training_checkpoints/Model_UNET_SGD_ch1_ks3_epoch40.pth.tar\"\n",
    "    checkpoint_file = os.path.join(base_dir, checkpoint_ref_filepath)\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # load additional customised info from checkpoint\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    ep_list = checkpoint['epoch_list']\n",
    "    loss_list = checkpoint['loss_list']\n",
    "    lr_list = checkpoint['lr_list']\n",
    "    epoch_res = EpochResult(_epoch_list =ep_list, _loss_list=loss_list, _lr_list=lr_list)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    epoch_start = epoch_res.epoch_list[-1] + 1\n",
    "else:\n",
    "    print(\"Unet3D - was initialised with weight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e6yaRp6W2ic"
   },
   "source": [
    "## Check Points filename\n",
    "- it is configurable for channel selector\n",
    "- kernel size of double conv\n",
    "- Adamn or SGD info is at the filename path\n",
    "- Use of CV Transpose or Upsample is also considered in the naming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUDLvdRNsKR0"
   },
   "source": [
    "## Training params\n",
    "Batch size used  \n",
    "- channel selector 0: batch size 6\n",
    "- channel selector 1: batch size 3\n",
    "- channel selector 2: batch size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_ji-5Jeo7PZ"
   },
   "source": [
    "## Dataset into Dataloader\n",
    "- Dataloader allow setting of batch size, which is another useful parameter for training.\n",
    "- shuffle allow data change of data orders, only useful for data training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700319880699,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "tyEc7vbXjOOe"
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "total_batches = math.ceil(len(training_data) / batch_size)\n",
    "num_epochs = 100\n",
    "model_unet_save_path = os.path.join(base_dir,\"training_checkpoints/Model_UNET_ch{}_ks{}_epoch{}.pth.tar\")\n",
    "if is_simplified:\n",
    "    model_unet_save_path = os.path.join(base_dir,\"training_checkpoints/Model_UNET_ch{}_ks{}_up_epoch{}.pth.tar\")\n",
    "\n",
    "if not is_ADAM:\n",
    "    model_unet_save_path = os.path.join(base_dir,\"training_checkpoints/Model_UNET_ch{}_ks{}_SGD_epoch{}.pth.tar\")\n",
    "    if is_simplified:\n",
    "        model_unet_save_path = os.path.join(base_dir,\"training_checkpoints/Model_UNET_ch{}_ks{}_SGD_up_epoch{}.pth.tar\")\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7CVwkBgsy9L"
   },
   "source": [
    "## Training Loop\n",
    "- Cross validation during training is commented out. This is because training is extremely costly and the team has already used Colab GPU Tesla T4 for the task.\n",
    "- Please note that compute unit is not free in Colab.\n",
    "- The loop save model's weight at every epoch.\n",
    "- Therefore, it allows termination of training at anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "executionInfo": {
     "elapsed": 25066,
     "status": "error",
     "timestamp": 1700319905761,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "owyRGaKGrRgG",
    "outputId": "214ffcda-ab72-4e3a-f844-90bfaa54cb86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31/100 batch:0/34   Loss:0.0592  avg batch time:18.1 LR=0.000204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dbb54febe686>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_time_start = time.time()\n",
    "batches_per_epoch = len(train_loader)\n",
    "\n",
    "for epoch in range(epoch_start, num_epochs):\n",
    "    model.train()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        images, masks = batch\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        masks = masks.long().squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, masks)\n",
    "        running_loss = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_processed_batches = (epoch - epoch_start) * batches_per_epoch + 1 + batch_idx\n",
    "        avg_batch_time = (time.time() - train_time_start) / total_processed_batches\n",
    "        if batch_idx % 5 == 0:\n",
    "            print(\"Epoch:{}/{} batch:{}/{}   Loss:{:.4f}  avg batch time:{:.1f} LR={:.6f}\".format(epoch, num_epochs, batch_idx, total_batches,running_loss, avg_batch_time, current_lr))\n",
    "    scheduler.step()\n",
    "    epoch_res.append_result(epoch, running_loss, current_lr)\n",
    "    model_checkpoint_path = model_unet_save_path.format(channel_selection, ks, epoch)\n",
    "    torch.save({'epoch_list': epoch_res.epoch_list, 'loss_list': epoch_res.loss_list,\n",
    "                'lr_list': epoch_res.lr_list, 'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()},model_checkpoint_path, _use_new_zipfile_serialization=True)\n",
    "    # Validation after each epoch\n",
    "    # model.eval()\n",
    "    # total_loss = 0.0\n",
    "    # with torch.no_grad():\n",
    "    #     for batch in test_loader:\n",
    "    #         images, masks = batch\n",
    "    #         images, masks = images.to(device), masks.to(device)\n",
    "    #         masks = masks.long().squeeze(1)\n",
    "\n",
    "    #         optimizer.zero_grad()\n",
    "    #         outputs = model(images.float())\n",
    "    #         loss = criterion(outputs, masks)\n",
    "    #         total_loss += loss.item()\n",
    "\n",
    "    # average_loss = total_loss / len(test_loader)\n",
    "    # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOWApDRsgZIWlJqL/tSpev+",
   "mount_file_id": "1GoF-_RRZBLN8DegMCNt95MTKRFsXu3tD",
   "provenance": [
    {
     "file_id": "10niTHkqNuQs02hCM9EaRSDmgLcKEFNPZ",
     "timestamp": 1700176080534
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
