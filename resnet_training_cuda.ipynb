{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3964,
     "status": "ok",
     "timestamp": 1700326247965,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "1rO4plCGF-ZO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import nibabel as nib\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14826,
     "status": "ok",
     "timestamp": 1700326262786,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "qkqxP2CBReBW",
    "outputId": "7997913d-9327-430c-f3d7-fff2c1593b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nilearn\n",
      "  Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.3.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.3)\n",
      "Requirement already satisfied: nibabel>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.0.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (23.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=3.2.0->nilearn) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Installing collected packages: nilearn\n",
      "Successfully installed nilearn-0.10.2\n"
     ]
    }
   ],
   "source": [
    "# Let's see whether Nilearn is installed\n",
    "try:\n",
    "    import nilearn\n",
    "except ImportError:\n",
    "    # if not, install it using pip\n",
    "    !pip install nilearn\n",
    "from nilearn.image import resample_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njiBF9qtUCkx"
   },
   "source": [
    "# General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dacl7HKER9o6"
   },
   "source": [
    "## Setup Directory for Dataset\n",
    "- Note that dataset used is transformed.\n",
    "- This is due to raw dataset is extremely large.\n",
    "- Due to limitation in computation, the project has focused on transformed, down-sampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1700326262787,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "9h6DHCGXR1ME"
   },
   "outputs": [],
   "source": [
    "base_dir = \"./\"\n",
    "raw_dataset_dir = \"dataset/\"\n",
    "transformed_dataset_dir_path = \"dataset/affine_transformed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLIzEB5kSaD6"
   },
   "source": [
    "## Google Colab\n",
    "- Google Colab is heavily used as complex model is required to perform training of model to perform data segmentation on 3D Voxel Space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700326262788,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "P0zpea5S6JsY",
    "outputId": "233370a8-33a3-4d44-82b9-2056a61104f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset folder exists, OK\n"
     ]
    }
   ],
   "source": [
    "is_colab = True\n",
    "if is_colab:\n",
    "    base_dir = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "    if not os.path.isdir(base_dir):\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "raw_dataset_dir = os.path.join(base_dir, raw_dataset_dir)\n",
    "transformed_dataset_dir_path = os.path.join(base_dir, transformed_dataset_dir_path)\n",
    "\n",
    "if os.path.isdir(raw_dataset_dir) and os.path.isdir(transformed_dataset_dir_path):\n",
    "    print(\"dataset folder exists, OK\")\n",
    "else:\n",
    "    raise Exception(\"check path for dataset:{} \\n path for transformed dataset: {}\"\n",
    "                    .format(raw_dataset_dir, transformed_dataset_dir_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMyMaMJbSrI_"
   },
   "source": [
    "## Import Custom Classes\n",
    "- Some help classes have been written\n",
    "- Resnet model generator is from Medical Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3006,
     "status": "ok",
     "timestamp": 1700326265789,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "2gDjgfZr6MyI",
    "outputId": "1f38fce9-a885-4aee-d3a3-d778c07747a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/\n"
     ]
    }
   ],
   "source": [
    "print(base_dir)\n",
    "sys.path.append(base_dir)\n",
    "from classes.dataset_utils.toTorchDataset import ProcessedKit23TorchDataset\n",
    "from classes.models import resnet_model_generator\n",
    "from classes.config_class import ProjectModelResnetConfig\n",
    "from classes.epoch_results import EpochResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz6vT0yzS7pC"
   },
   "source": [
    "# Get Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1700326266679,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "NXYOOVvxSpvt"
   },
   "outputs": [],
   "source": [
    "training_data = ProcessedKit23TorchDataset(train_data=True, test_size=0.25, dataset_dir =transformed_dataset_dir_path)\n",
    "test_data = ProcessedKit23TorchDataset(train_data=False, test_size=0.25, dataset_dir =transformed_dataset_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700326266679,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "cj4tvDq7wGzc",
    "outputId": "c3fd2a15-e374-48e4-f710-39049ee616a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dVrb-VMTJ52"
   },
   "source": [
    "# Generate the Resnet 50 Model\n",
    "- The Resnet 50 model is generated by using Medical Net's resnet_model_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7130,
     "status": "ok",
     "timestamp": 1700326273806,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "LW7XbLt-S2KF"
   },
   "outputs": [],
   "source": [
    "proj_config = ProjectModelResnetConfig(model_depth=50, no_cuda=False)\n",
    "proj_resnet_model, _ = resnet_model_generator.generate_model(proj_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700326273807,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "u9ai_YmrTauS"
   },
   "outputs": [],
   "source": [
    "proj_config.set_net_model(proj_resnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-kSKra5TXNa"
   },
   "source": [
    "## Loss function and Optimizer\n",
    "- Cross Entropy loss function is applied to this multiclasess problem.\n",
    "- SGD Optimiser is selected with learning rate 0.001, momentum 0.9 and weight decay 0.001.\n",
    "- The learning rate has decay setting or gamme 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4296,
     "status": "ok",
     "timestamp": 1700326278100,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "myKWkVGdTc_1"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = optim.SGD(proj_config.nn_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if not proj_config.no_cuda:\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyllkT7QT1s-"
   },
   "source": [
    "## Load Pretrained Weight or Load Checkpoint\n",
    "- Follow code block enables loading pretrained weight.\n",
    "- Alternatively, checkpoint of Resnet trained weight can be loaded for continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5183,
     "status": "ok",
     "timestamp": 1700326283280,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "mEzYwp3HTgUs",
    "outputId": "139f2b20-1a7e-4c3e-c576-a5e9e7b71175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/training_checkpoints/Model_resnet_50_epoch45.pth.tar\n"
     ]
    }
   ],
   "source": [
    "train_from_pretrained = False\n",
    "epoch_res = EpochResult()\n",
    "epoch_start = 0\n",
    "if train_from_pretrained:\n",
    "    print(\"loading from pretrained Med3D model\")\n",
    "    resnet10 = \"pretrainedModel/resnet_10_23dataset.pth\"\n",
    "    resnet50 = \"pretrainedModel/resnet_50_23dataset.pth\"\n",
    "    if proj_config.model_depth == 10:\n",
    "        pretrained_w = os.path.join(base_dir, resnet10)\n",
    "        proj_config.load_med3d_pretrain_weigth(pretrained_w)\n",
    "    elif proj_config.model_depth == 50:\n",
    "        pretrained_w = os.path.join(base_dir, resnet50)\n",
    "        proj_config.load_med3d_pretrain_weigth(pretrained_w)\n",
    "    else:\n",
    "        raise Exception(\"Only depth 10 and 50 are used for now.\")\n",
    "else:\n",
    "    # this continues from certain training points\n",
    "    checkpoint_dir = \"training_checkpoints/Model_resnet_50_epoch45.pth.tar\"\n",
    "    pretrained_w = os.path.join(base_dir, checkpoint_dir)\n",
    "    checkpoint, epoch_res = proj_config.load_weight_from_epoch(pretrained_w)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "    epoch_start = epoch_res.epoch_list[-1] + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w1fQnzONXTW"
   },
   "source": [
    "# Data Loader for training\n",
    "- train data is loaded to dataloader.\n",
    "- batch size and num_worker are fixed to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700326283280,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "NU4iX4vzGEif"
   },
   "outputs": [],
   "source": [
    "# data_loader = DataLoader(training_data, batch_size=proj_config.batch_size, shuffle=True, num_workers=proj_config.num_workers, pin_memory=proj_config.pin_memory)\n",
    "data_loader = DataLoader(training_data, batch_size=1, shuffle=True, num_workers=1, pin_memory=proj_config.pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700326283281,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "WBUxNNz6oc7i"
   },
   "outputs": [],
   "source": [
    "if is_colab:\n",
    "    proj_config.model_save_path = os.path.join(base_dir,\"training_checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjpNnuaUUt9o"
   },
   "source": [
    "# Resnet Training Loop\n",
    "- Below is traiing loop for Resnet.\n",
    "- The Medical Net Resnet model would output result that has smaller in size/shape.\n",
    "- Therefore, the output needs to scaled.\n",
    "- Learning Rate, epoch number and loss are recorded in the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 97407,
     "status": "error",
     "timestamp": 1700326380683,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "dNNhAonkew4G",
    "outputId": "a914757c-ce26-431a-c713-71bfbac994eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch=   46 Learning Rate=[0.000629823631203232]\n",
      "Epoch:46 Batch:0 loss = 0.01390, avg_batch_time = 11.27008\n",
      "Epoch:46 Batch:25 loss = 0.00834, avg_batch_time = 2.43808\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b359e72d8a26>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproj_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mori_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mori_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mori_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mori_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_time_start = time.time()\n",
    "batches_per_epoch = len(data_loader)\n",
    "\n",
    "for epoch in range(epoch_start, proj_config.max_epoch):\n",
    "    current_lr = scheduler.get_last_lr()\n",
    "    running_loss = None\n",
    "    print(\"current epoch={:5d} Learning Rate={}\".format(epoch, current_lr))\n",
    "\n",
    "    for batch_idx, batch_data  in enumerate(data_loader):\n",
    "        imgs, segs = batch_data\n",
    "        if not proj_config.no_cuda:\n",
    "            imgs, segs = imgs.cuda(), segs.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_preds = proj_config.nn_model(imgs.float())\n",
    "\n",
    "        [n, _, z_size, y_size, x_size] = y_preds.shape\n",
    "\n",
    "        resized_segs = np.zeros([n, z_size, y_size, x_size])\n",
    "        for idx in range(n):\n",
    "            seg = segs[idx][0]\n",
    "            if not proj_config.no_cuda:\n",
    "                seg = seg.to('cpu')\n",
    "            [ori_z, ori_y, ori_x] = seg.shape\n",
    "            scale = [z_size/ori_z, y_size/ori_y, x_size/ori_x]\n",
    "            # this_affine = np.array([[scale[0], 0, 0],[0, scale[1], 0],[0, 0, scale[2]]])\n",
    "            # resized_segs[idx] = ndimage.affine_transform(seg, this_affine, output_shape=resized_segs[idx].shape, cval=0)\n",
    "            resized_segs[idx] = ndimage.zoom(seg, scale, order=0)\n",
    "\n",
    "        resized_segs = torch.tensor(resized_segs).to(torch.int64)\n",
    "        if not proj_config.no_cuda:\n",
    "            resized_segs = resized_segs.cuda()\n",
    "        loss = criterion(y_preds, resized_segs)\n",
    "        running_loss = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_processed_batches = (epoch - epoch_start) * batches_per_epoch + 1 + batch_idx\n",
    "        avg_batch_time = (time.time() - train_time_start) / total_processed_batches\n",
    "        if batch_idx % 25 == 0:\n",
    "            print(\"Epoch:{} Batch:{} loss = {:.5f}, avg_batch_time = {:.5f}\".format(epoch, batch_idx, running_loss, avg_batch_time))\n",
    "    scheduler.step()\n",
    "    epoch_res.append_result(epoch, running_loss, current_lr)\n",
    "    model_checkpoint_path = proj_config.save_checkpoint_pathname(epoch, with_Datetime=False)\n",
    "    torch.save({'epoch_list': epoch_res.epoch_list, 'loss_list': epoch_res.loss_list, 'lr_list': epoch_res.lr_list,\n",
    "                'state_dict': proj_config.nn_model.state_dict(),'optimizer': optimizer.state_dict()},model_checkpoint_path, _use_new_zipfile_serialization=True)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1700326380684,
     "user": {
      "displayName": "Andrew Chin Chai",
      "userId": "11426134509903437449"
     },
     "user_tz": -660
    },
    "id": "fHLBChO3c8p-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOYETaTkDfzhiO921GVrDkH",
   "gpuType": "T4",
   "mount_file_id": "11s_0TXdt0qm7e-NV0tx-IJ_l7e93YfFd",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
